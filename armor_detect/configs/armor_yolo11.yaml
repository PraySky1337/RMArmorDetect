# Armor Detection Model Configuration
# Based on YOLO11-pose with dual classification branches (number + color)
# Keypoint-only detection without bounding boxes

# Model scale: n(nano), s(small), m(medium), l(large), x(xlarge)
scale: 's'

# Class configuration
nc: 64            # Total classes (nc_num * nc_color * nc_size = 8 * 4 * 2)
nc_num: 8         # Number classes (G, 1, 2, 3, 4, 5, O, B)
nc_color: 4       # Color classes (B, R, N, P)
nc_size: 2        # Size classes (s=small, b=big)
kpt_shape: [4, 2] # 4 keypoints, 2D coordinates (x, y)

# WingLoss parameters for keypoint regression
# omega应该与图像尺寸成比例，imgsz=416时建议50-100
wing_omega: 30.0  # 降低分界点，让训练更稳定
wing_epsilon: 2.0 # Smoothing parameter for logarithmic part

# Loss weights - 平衡各个分支
# 注意：分类损失现在对所有anchor计算（包括背景），权重需要降低
pose: 5.0         # keypoint loss权重
kobj: 1.0         # Keypoint objectness weight
cls: 1.0          # 数字分类loss权重（降低，因为负样本也参与）
color: 0.75       # 颜色分类权重（降低）
size: 0.75        # 尺寸分类权重（降低）

# Focal Loss parameters
focal_gamma: 1.5  # Gamma for hard example mining

# Model scaling constants
# Format: [depth, width, max_channels]
scales:
  n: [0.375, 0.1875, 512]  # Nano: fastest, smallest
  s: [0.50, 0.50, 1024]    # Small: balanced
  m: [0.50, 1.00, 512]     # Medium: higher accuracy
  l: [1.00, 1.00, 512]     # Large: high accuracy
  x: [1.00, 1.50, 512]     # XLarge: highest accuracy

# YOLO11 Backbone with C3k2 + SPPF
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [32, 3, 2]]         # 0-P1/2: Initial conv
  - [-1, 1, Conv, [64, 3, 2]]         # 1-P2/4: Downsample
  - [-1, 1, C3k2, [128, False, 0.25]] # 2: Lightweight C3k2
  - [-1, 1, Conv, [128, 3, 2]]        # 3-P3/8: Feature scale 1
  - [-1, 1, C3k2, [256, False, 0.25]] # 4: Lightweight C3k2
  - [-1, 1, Conv, [256, 3, 2]]        # 5-P4/16: Feature scale 2
  - [-1, 1, C3k2, [256, True]]        # 6: Standard C3k2
  - [-1, 1, Conv, [512, 3, 2]]        # 7-P5/32: Feature scale 3
  - [-1, 1, C3k2, [512, True]]        # 8: Standard C3k2
  - [-1, 1, SPPF, [512, 5]]           # 9: Spatial Pyramid Pooling Fast
  - [-1, 1, C3k2, [512, False]]       # 10: Final backbone layer

# YOLO11 Head with FPN + PAN structure
head:
  # FPN: Top-down pathway
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]]        # cat backbone P4
  - [-1, 1, C3k2, [256, False]]      # 12: P4 fusion

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]]        # cat backbone P3
  - [-1, 1, C3k2, [128, False]]      # 15: P3/8 (small objects)

  # PAN: Bottom-up pathway
  - [-1, 1, Conv, [128, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]       # cat head P4
  - [-1, 1, C3k2, [256, False]]      # 18: P4 fusion

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 10], 1, Concat, [1]]       # cat head P5
  - [-1, 1, C3k2, [512, True]]       # 21: P5 (large objects)

  # Detection head: ArmorPoseHead with triple classification
  # Args: [nc_num, nc_color, nc_size, kpt_shape]
  # nc_num=8: G(0), 1(1), 2(2), 3(3), 4(4), 5(5), O(6), B(7)
  - [[15, 18, 21], 1, Pose, [8, 4, 2, [4, 2]]]
