# GPU æ˜¾å­˜å ç”¨ä½é—®é¢˜è¯Šæ–­

## é—®é¢˜æè¿°
- ç°è±¡ï¼šGPU æ˜¾å­˜åªå ç”¨ 6.9Gï¼Œæ­£å¸¸åº”è¯¥ 18G+
- æ€€ç–‘ï¼šGPU åœ¨ç­‰å¾…æ•°æ®ï¼ˆæ•°æ®åŠ è½½æˆä¸ºç“¶é¢ˆï¼‰
- é…ç½®ï¼štrain_config.yaml ä¸­è®¾ç½®äº† `cache: "ram"`

## å·²å®Œæˆçš„è¯Šæ–­å·¥ä½œ

### 1. ç¡®è®¤é…ç½®
- âœ… train_config.yaml ä¸­ `cache: "ram"` é…ç½®æ­£ç¡®
- âœ… workers: 32, batch: 256, imgsz: 416

### 2. ç¡®è®¤å†…å­˜å®¹é‡
- ç³»ç»Ÿæ€»å†…å­˜ï¼š30.6GB
- å½“å‰å¯ç”¨ï¼š24.3GB
- æ•°æ®é›†ï¼š24749 å¼ å›¾ç‰‡
- é¢„ä¼°éœ€æ±‚ï¼š17.95GB (å« 50% safety margin)
- **ç»“è®ºï¼šå†…å­˜è¶³å¤Ÿ**

### 3. ç¡®è®¤ç¼“å­˜é€»è¾‘
æ£€æŸ¥äº†ä»¥ä¸‹æ–‡ä»¶çš„ç¼“å­˜å®ç°ï¼š
- `ultralytics/data/base.py`: BaseDataset çš„ç¼“å­˜é€»è¾‘
- `ultralytics/data/build.py`: DataLoader æ„å»ºé€»è¾‘
- `ultralytics/data/dataset.py`: YOLODataset å®ç°

**ç¼“å­˜æµç¨‹ï¼š**
```python
# 1. è§£æ cache å‚æ•°
self.cache = "ram" if cache == "ram" else None

# 2. æ£€æŸ¥å†…å­˜æ˜¯å¦è¶³å¤Ÿ
if self.cache == "ram" and self.check_cache_ram():
    # 3. æ‰§è¡Œç¼“å­˜
    self.cache_images()  # ä¼šæŠŠæ‰€æœ‰å›¾ç‰‡è¯»å…¥ self.ims åˆ—è¡¨
```

### 4. æ·»åŠ è¯Šæ–­æ—¥å¿—
åœ¨ `ultralytics/data/base.py` ä¸­æ·»åŠ äº†è¯Šæ–­æ—¥å¿—ï¼š
- æ˜¾ç¤º cache é…ç½®
- æ˜¾ç¤ºå†…å­˜æ£€æŸ¥ç»“æœï¼ˆéœ€æ±‚ vs å¯ç”¨ï¼‰
- æ˜¾ç¤ºç¼“å­˜ç»“æœï¼ˆå·²ç¼“å­˜æ•°é‡ï¼‰

**ä¿®æ”¹çš„æ–‡ä»¶ï¼š**
- `/home/ljy/Desktop/RMArmorDetect/ultralytics/data/base.py`

## å¯èƒ½çš„é—®é¢˜ç‚¹

### é—®é¢˜1: check_cache_ram() å¯èƒ½è¿”å› False
**åŸå› ï¼š**
- safety_margin=0.5 (é»˜è®¤)
- éœ€è¦ 17.95GBï¼Œå½“å‰å¯ç”¨ 24.3GB â†’ **åº”è¯¥é€šè¿‡**
- ä½†å¦‚æœåœ¨å¤š GPU è®­ç»ƒæ—¶ï¼Œæ¯ä¸ªè¿›ç¨‹éƒ½ä¼šæ£€æŸ¥ï¼Œå¯èƒ½å¯¼è‡´å†…å­˜ä¸è¶³

**éªŒè¯æ–¹æ³•ï¼š**
æŸ¥çœ‹è®­ç»ƒæ—¥å¿—ä¸­æ˜¯å¦æœ‰ä»¥ä¸‹ä¿¡æ¯ï¼š
```
train: RAM check: need 17.9GB, available 24.3GB / 30.6GB total
train: âœ… RAM cache check passed, starting to cache 22541 images...
train: âœ… Cached 22541/22541 images to RAM
```

å¦‚æœçœ‹åˆ° `âŒ RAM cache requested but check_cache_ram() failed`ï¼Œè¯´æ˜å†…å­˜æ£€æŸ¥å¤±è´¥ã€‚

### é—®é¢˜2: å¤šè¿›ç¨‹ DataLoader çš„å†…å­˜å…±äº«
**å½“å‰é…ç½®ï¼š**
- workers=32 (è¿‡å¤šï¼Ÿ)
- prefetch_factor=4
- persistent_workers=True

**æ½œåœ¨é—®é¢˜ï¼š**
1. è™½ç„¶ cache="ram" åœ¨ä¸»è¿›ç¨‹åŠ è½½äº†æ‰€æœ‰å›¾ç‰‡
2. ä½†åˆ›å»º 32 ä¸ª worker è¿›ç¨‹æ—¶ï¼š
   - Linux fork: worker ä¼šç»§æ‰¿ä¸»è¿›ç¨‹å†…å­˜ï¼ˆcopy-on-writeï¼‰ï¼Œ**åº”è¯¥æ­£å¸¸å·¥ä½œ**
   - ä½† prefetch_factor=4 æ„å‘³ç€æ¯ä¸ª worker é¢„å– 4 ä¸ª batch
   - 32 workers * 4 * batch_size=256 = å¯èƒ½çš„å†…å­˜å‹åŠ›

**å»ºè®®ï¼š**
- å¦‚æœ cache="ram" ç”Ÿæ•ˆï¼Œå¯ä»¥é™ä½ workers æ•°é‡ï¼ˆä¾‹å¦‚ 8-16ï¼‰
- å› ä¸ºæ•°æ®å·²åœ¨å†…å­˜ï¼Œç“¶é¢ˆä¸åœ¨ç£ç›˜ I/Oï¼Œè€Œåœ¨æ•°æ®å¢å¼ºå’Œä¼ è¾“

### é—®é¢˜3: æ•°æ®å¢å¼ºå¼€é”€
å³ä½¿ cache="ram" ç”Ÿæ•ˆï¼ŒDataLoader æ¯æ¬¡è¿˜æ˜¯è¦ï¼š
1. ä» self.ims[i] è¯»å–ç¼“å­˜çš„å›¾ç‰‡
2. åº”ç”¨æ•°æ®å¢å¼ºï¼ˆMosaic, MixUp, HSV, Affine ç­‰ï¼‰
3. è½¬æ¢ä¸º Tensor
4. ä¼ è¾“åˆ° GPU

**å½“å‰å¢å¼ºé…ç½®ï¼ˆtrain_config.yamlï¼‰ï¼š**
```yaml
mosaic: 1.0
mixup: 0.1
hsv_h: 0.08, hsv_s: 0.9, hsv_v: 0.9
degrees: 5.0, translate: 0.2, scale: 0.5
```

è¿™äº›å¢å¼ºæ“ä½œåœ¨ CPU ä¸Šæ‰§è¡Œï¼Œå¯èƒ½æˆä¸ºç“¶é¢ˆã€‚

## ä¸‹ä¸€æ­¥è¯Šæ–­æ­¥éª¤

### æ­¥éª¤1: è¿è¡Œè¯Šæ–­è„šæœ¬ï¼ˆæ— éœ€è®­ç»ƒï¼‰
```bash
# åœ¨è®­ç»ƒç¯å¢ƒä¸­è¿è¡Œ
python test_cache_simple.py
```

è¿™ä¸ªè„šæœ¬ä¼šï¼š
1. åˆ›å»º Dataset (cache="ram")
2. ç›‘æ§å†…å­˜å˜åŒ–
3. æ£€æŸ¥æœ‰å¤šå°‘å›¾ç‰‡è¢«ç¼“å­˜
4. æµ‹è¯•æ•°æ®åŠ è½½é€Ÿåº¦

**é¢„æœŸè¾“å‡ºï¼š**
- å†…å­˜å¢é•¿ 12-18GB
- å·²ç¼“å­˜å›¾ç‰‡æ•° = æ€»å›¾ç‰‡æ•°
- æ•°æ®åŠ è½½é€Ÿåº¦ < 5ms/å¼ 

### æ­¥éª¤2: æ£€æŸ¥è®­ç»ƒæ—¥å¿—
ä¸‹æ¬¡è®­ç»ƒæ—¶ï¼ŒæŸ¥çœ‹æ—¥å¿—å¼€å¤´æ˜¯å¦æœ‰ï¼š
```
train: Cache mode: ram (input: ram)
train: RAM check: need X.XGB, available Y.YGB / Z.ZGB total
train: âœ… RAM cache check passed, starting to cache XXXXX images...
train: Caching images (X.XGB RAM): 100%|...
train: âœ… Cached XXXXX/XXXXX images to RAM
```

å¦‚æœæ²¡æœ‰è¿™äº›æ—¥å¿—ï¼Œæˆ–è€…çœ‹åˆ°é”™è¯¯ä¿¡æ¯ï¼Œè¯´æ˜ç¼“å­˜æœªç”Ÿæ•ˆã€‚

### æ­¥éª¤3: å¦‚æœç¼“å­˜å·²ç”Ÿæ•ˆä½† GPU ä»ç­‰å¾…
å¯èƒ½çš„ä¼˜åŒ–ï¼š

**3.1 é™ä½ workers æ•°é‡**
```yaml
# train_config.yaml
workers: 8  # ä» 32 é™åˆ° 8
```
ç†ç”±ï¼šæ•°æ®å·²åœ¨å†…å­˜ï¼Œä¸éœ€è¦å¤ªå¤š I/O çº¿ç¨‹

**3.2 ä½¿ç”¨ prefetch_factor**
å½“å‰ build.py ä¸­å·²è®¾ç½® `prefetch_factor=4`ï¼Œè¿™å·²ç»æ˜¯ä¼˜åŒ–è¿‡çš„ã€‚

**3.3 æ£€æŸ¥æ˜¯å¦æ˜¯æ•°æ®å¢å¼ºç“¶é¢ˆ**
ä¸´æ—¶å…³é—­å¢å¼ºæµ‹è¯•ï¼š
```yaml
mosaic: 0.0
mixup: 0.0
```

**3.4 æ£€æŸ¥ batch size æ˜¯å¦è¿‡å¤§**
```yaml
batch: 128  # ä» 256 é™åˆ° 128
```

**3.5 ä½¿ç”¨ GPU æ•°æ®å¢å¼ºï¼ˆå¦‚æœæ”¯æŒï¼‰**
æŸäº›å¢å¼ºå¯ä»¥åœ¨ GPU ä¸Šåšï¼Œä½† YOLO é»˜è®¤åœ¨ CPUã€‚

### æ­¥éª¤4: ç›‘æ§è®­ç»ƒæ—¶çš„ç³»ç»ŸçŠ¶æ€
è®­ç»ƒæ—¶è¿è¡Œï¼š
```bash
# ç»ˆç«¯1ï¼šç›‘æ§ GPU
watch -n 1 nvidia-smi

# ç»ˆç«¯2ï¼šç›‘æ§å†…å­˜å’Œ CPU
watch -n 1 'free -h && echo && ps aux | grep python | head -5'

# ç»ˆç«¯3ï¼šç›‘æ§ IO
iostat -x 1
```

è§‚å¯Ÿï¼š
- GPU åˆ©ç”¨ç‡ä½ + CPU åˆ©ç”¨ç‡é«˜ â†’ CPU æ•°æ®å¢å¼ºç“¶é¢ˆ
- GPU åˆ©ç”¨ç‡ä½ + IO ç­‰å¾…é«˜ â†’ ç£ç›˜ I/O ç“¶é¢ˆï¼ˆè¯´æ˜ cache æœªç”Ÿæ•ˆï¼‰
- GPU åˆ©ç”¨ç‡ä½ + å†…å­˜å¸¦å®½é«˜ â†’ å†…å­˜ä¼ è¾“ç“¶é¢ˆ

## æ€»ç»“

**å·²æ·»åŠ çš„è¯Šæ–­åŠŸèƒ½ï¼š**
1. âœ… BaseDataset ä¼šæ‰“å° cache æ¨¡å¼
2. âœ… ä¼šæ‰“å°å†…å­˜æ£€æŸ¥ç»“æœ
3. âœ… ä¼šæ‰“å°ç¼“å­˜å®ŒæˆçŠ¶æ€

**å¾…éªŒè¯ï¼š**
1. è¿è¡Œ test_cache_simple.py ç¡®è®¤ç¼“å­˜æ˜¯å¦ç”Ÿæ•ˆ
2. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—ç¡®è®¤è¯Šæ–­è¾“å‡º
3. æ ¹æ®è¯Šæ–­ç»“æœè°ƒæ•´ workers / batch / augmentation

**é«˜æ¦‚ç‡åŸå› æ’åºï¼š**
1. ğŸ”¥ ç¼“å­˜æœªç”Ÿæ•ˆï¼ˆå†…å­˜æ£€æŸ¥å¤±è´¥æˆ–å¤šè¿›ç¨‹é—®é¢˜ï¼‰â†’ è¿è¡Œè¯Šæ–­è„šæœ¬éªŒè¯
2. ğŸ”¥ CPU æ•°æ®å¢å¼ºæˆä¸ºç“¶é¢ˆï¼ˆworkers=32 å¯èƒ½è¿‡å¤šæˆ–è¿‡å°‘ï¼‰â†’ è°ƒæ•´ workers
3. âš ï¸ Batch size å¤ªå¤§å¯¼è‡´ä¼ è¾“æ—¶é—´é•¿ â†’ é™ä½ batch æµ‹è¯•
4. âš ï¸ å…¶ä»–æœªçŸ¥ç“¶é¢ˆ â†’ éœ€è¦ profiling

**ç«‹å³è¡ŒåŠ¨ï¼š**
```bash
# 1. è¿è¡Œè¯Šæ–­è„šæœ¬
python test_cache_simple.py > cache_test.log 2>&1

# 2. æ£€æŸ¥è¾“å‡º
cat cache_test.log | grep -E "Cache mode|RAM check|Cached|ç»“æœ|ç»“è®º"

# 3. å¦‚æœç¼“å­˜ç”Ÿæ•ˆï¼Œé‡æ–°è®­ç»ƒå¹¶è§‚å¯Ÿæ—¥å¿—
# 4. å¦‚æœç¼“å­˜æœªç”Ÿæ•ˆï¼ŒæŸ¥çœ‹æ—¥å¿—ä¸­çš„é”™è¯¯ä¿¡æ¯
```
