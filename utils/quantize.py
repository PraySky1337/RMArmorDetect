# """ONNX æ¨¡å‹é™æ€é‡åŒ–è„šæœ¬"""

# from __future__ import annotations

# import os
# import cv2
# import numpy as np
# from pathlib import Path
# from onnxruntime.quantization import quantize_static, CalibrationDataReader, QuantType, QuantFormat

# # ================== é…ç½® ==================
# INPUT_MODEL = "pose_simplified.onnx"      # è¾“å…¥ ONNX æ¨¡å‹
# OUTPUT_MODEL = "pose_int8.onnx"           # è¾“å‡ºé‡åŒ–æ¨¡å‹
# CALIBRATION_DIR = "../img_quantize"       # æ ¡å‡†å›¾åƒç›®å½•
# IMGSZ = 416                               # è¾“å…¥å°ºå¯¸
# NUM_CALIBRATION = 100                     # æ ¡å‡†å›¾åƒæ•°é‡


# class ImageCalibrationDataReader(CalibrationDataReader):
#     """ä»å›¾åƒç›®å½•è¯»å–æ ¡å‡†æ•°æ®"""

#     def __init__(self, calibration_dir: str, imgsz: int = 416, num_samples: int = 100):
#         self.imgsz = imgsz
#         self.idx = 0

#         # è·å–å›¾åƒåˆ—è¡¨
#         valid_exts = {".jpg", ".jpeg", ".png", ".bmp"}
#         image_dir = Path(calibration_dir)
#         self.image_files = [
#             f for f in image_dir.iterdir()
#             if f.suffix.lower() in valid_exts
#         ][:num_samples]

#         print(f"ğŸ“ æ‰¾åˆ° {len(self.image_files)} å¼ æ ¡å‡†å›¾åƒ")

#     def preprocess(self, image_path: Path) -> np.ndarray:
#         """é¢„å¤„ç†å›¾åƒä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼"""
#         img = cv2.imread(str(image_path))
#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

#         # Resize with letterbox
#         h, w = img.shape[:2]
#         scale = min(self.imgsz / h, self.imgsz / w)
#         nh, nw = int(h * scale), int(w * scale)
#         img = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_LINEAR)

#         # Pad to square
#         pad_h = (self.imgsz - nh) // 2
#         pad_w = (self.imgsz - nw) // 2
#         img_padded = np.full((self.imgsz, self.imgsz, 3), 114, dtype=np.uint8)
#         img_padded[pad_h:pad_h + nh, pad_w:pad_w + nw] = img

#         # Normalize and transpose
#         img_padded = img_padded.astype(np.float32) / 255.0
#         img_padded = img_padded.transpose(2, 0, 1)  # HWC -> CHW
#         img_padded = np.expand_dims(img_padded, axis=0)  # Add batch dim

#         return img_padded

#     def get_next(self) -> dict | None:
#         if self.idx >= len(self.image_files):
#             return None

#         image_path = self.image_files[self.idx]
#         self.idx += 1

#         try:
#             data = self.preprocess(image_path)
#             # è¾“å…¥åç§°éœ€è¦ä¸ ONNX æ¨¡å‹åŒ¹é…
#             return {"images": data}
#         except Exception as e:
#             print(f"âš ï¸ è·³è¿‡å›¾åƒ {image_path}: {e}")
#             return self.get_next()

#     def rewind(self):
#         self.idx = 0


# def quantize_model(
#     input_model: str,
#     output_model: str,
#     calibration_dir: str,
#     imgsz: int = 416,
#     num_calibration: int = 100,
# ):
#     """æ‰§è¡Œé™æ€é‡åŒ–"""

#     print(f"ğŸ“¦ è¾“å…¥æ¨¡å‹: {input_model}")
#     print(f"ğŸ“¦ è¾“å‡ºæ¨¡å‹: {output_model}")
#     print(f"ğŸ“ è¾“å…¥å°ºå¯¸: {imgsz}")

#     # åˆ›å»ºæ ¡å‡†æ•°æ®è¯»å–å™¨
#     calibration_reader = ImageCalibrationDataReader(
#         calibration_dir=calibration_dir,
#         imgsz=imgsz,
#         num_samples=num_calibration,
#     )

#     # æ‰§è¡Œé™æ€é‡åŒ–
#     print("ğŸ”„ å¼€å§‹é‡åŒ–...")
#     quantize_static(
#         model_input=input_model,
#         model_output=output_model,
#         calibration_data_reader=calibration_reader,
#         quant_format=QuantFormat.QDQ,  # é‡åŒ–æ ¼å¼
#         weight_type=QuantType.QInt8,   # æƒé‡é‡åŒ–ç±»å‹
#         activation_type=QuantType.QUInt8,  # æ¿€æ´»é‡åŒ–ç±»å‹
#         per_channel=True,              # é€é€šé“é‡åŒ–ï¼ˆæ›´ç²¾ç¡®ï¼‰
#         reduce_range=False,
#     )

#     print(f"âœ… é‡åŒ–å®Œæˆ: {output_model}")

#     # æ‰“å°æ¨¡å‹å¤§å°å¯¹æ¯”
#     input_size = os.path.getsize(input_model) / (1024 * 1024)
#     output_size = os.path.getsize(output_model) / (1024 * 1024)
#     print(f"ğŸ“Š åŸå§‹å¤§å°: {input_size:.2f} MB")
#     print(f"ğŸ“Š é‡åŒ–å¤§å°: {output_size:.2f} MB")
#     print(f"ğŸ“Š å‹ç¼©æ¯”: {input_size / output_size:.2f}x")


# if __name__ == "__main__":
#     import argparse

#     parser = argparse.ArgumentParser(description="ONNX æ¨¡å‹é™æ€é‡åŒ–")
#     parser.add_argument("--input", type=str, default=INPUT_MODEL, help="è¾“å…¥ ONNX æ¨¡å‹è·¯å¾„")
#     parser.add_argument("--output", type=str, default=OUTPUT_MODEL, help="è¾“å‡ºé‡åŒ–æ¨¡å‹è·¯å¾„")
#     parser.add_argument("--calib-dir", type=str, default=CALIBRATION_DIR, help="æ ¡å‡†å›¾åƒç›®å½•")
#     parser.add_argument("--imgsz", type=int, default=IMGSZ, help="è¾“å…¥å›¾åƒå°ºå¯¸")
#     parser.add_argument("--num-calib", type=int, default=NUM_CALIBRATION, help="æ ¡å‡†å›¾åƒæ•°é‡")
#     args = parser.parse_args()

#     quantize_model(
#         input_model=args.input,
#         output_model=args.output,
#         calibration_dir=args.calib_dir,
#         imgsz=args.imgsz,
#         num_calibration=args.num_calib,
#     )

from onnxruntime.quantization import quantize_dynamic, QuantType

quantize_dynamic(
      model_input="pose_simplified.onnx",
      model_output="pose_int8.onnx",
      weight_type=QuantType.QInt8
  )
print("âœ… é‡åŒ–å®Œæˆ")